{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating different penalty terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "We apply our model in a real data example with two real measurement instruments, i.e., without artificial modifications, where discrepancies between measurement instruments could arise due to more complex reasons. We consider data from the HFMSE and RULM measurement instruments in the SMArtCARE data as described in Section 3.1 in the manuscript.\n",
    "\n",
    "On this dataset, we compare different versions of penalties in our approach with respect to their effectiveness in achieving a close alignment, as described in Section 3.4 in the manuscript. \n",
    "Specifically, we train the model with four different loss function versions, using \n",
    " 1. neither the adversarial penalty term nor the ODE penalty,\n",
    " 2. only the ODE penalty, i.e., $\\alpha=0, \\beta \\neq 0$,\n",
    " 3. only the adversarial penalty, i.e., $\\alpha \\neq 0, \\beta=0$, \n",
    " 4. both penalty terms, i.e., $\\alpha, \\beta \\neq 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We start by loading the Julia environment, the necessary package libraries and functions from the `src` directory that we will use in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Julia environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd(@__DIR__)\n",
    "\n",
    "using Pkg;\n",
    "Pkg.activate(\"../.\")\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using Dates\n",
    "using DataFrames\n",
    "using Distributions\n",
    "using Random\n",
    "using GLM\n",
    "using Flux\n",
    "using LaTeXStrings\n",
    "using LinearAlgebra\n",
    "using Measures\n",
    "using Parameters\n",
    "using Plots \n",
    "using ProgressMeter\n",
    "using StatsBase\n",
    "gr() # setting the plotting backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcedir = \"../src/\"\n",
    "include(joinpath(sourcedir, \"load_data.jl\"))\n",
    "include(joinpath(sourcedir, \"model.jl\"))\n",
    "include(joinpath(sourcedir, \"ODE_solutions.jl\"))\n",
    "include(joinpath(sourcedir, \"training.jl\"))\n",
    "include(joinpath(sourcedir, \"eval_penalties.jl\"))\n",
    "include(joinpath(sourcedir, \"plot_latent.jl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing data \n",
    "\n",
    "We load the baseline information and the timedependent data separately. We subset to the RULM and HFMSE measurements, respectively, then prepare the data for the training process (for details, see the corresponding functions or the description in Section 3.1 in the manuscript)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = joinpath(\"../dataset/\")\n",
    "\n",
    "baseline_df = CSV.File(string(data_path, \"baseline_df.csv\"), truestrings = [\"TRUE\", \"M\"], falsestrings = [\"FALSE\", \"F\"], missingstring = [\"NA\"], decimal=',') |> DataFrame\n",
    "timedepend_df = CSV.File(string(data_path, \"timedepend_df.csv\"), truestrings = [\"TRUE\"], falsestrings = [\"FALSE\"], missingstring = [\"NA\"], decimal=',') |> DataFrame\n",
    "\n",
    "# remove \"Column1\"\n",
    "baseline_df = baseline_df[:,2:end]\n",
    "timedepend_df = timedepend_df[:,2:end]\n",
    "\n",
    "other_vars = [\"patient_id\", \"months_since_1st_test\", \"feeding_tube\", \n",
    "            \"scoliosis_yn\", \"pain_yn\", \"fatigue_yn\", \"ventilation\", \"adverse_event\", \n",
    "            \"fvc_yn\", \"fvc_percent\",\n",
    "            \"gen_impr\", \"mf_impr\", \"rf_impr\"\n",
    "]\n",
    "\n",
    "baseline_vars = names(baseline_df)[findall(x -> !(x ∈ [\"cohort\", \"baseline_date\"]), names(baseline_df))]\n",
    "\n",
    "test1=\"hfmse\"\n",
    "test2=\"rulm\"\n",
    "mixeddata = get_data_tests(timedepend_df, baseline_df, \n",
    "    other_vars, baseline_vars; \n",
    "    test1=test1, test2=test2, remove_lessthan1=true\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we set up the directory structure for saving the reults:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!isdir(\"../results\") && mkdir(\"../results\")\n",
    "save_eval_dir = \"../results/penalties\"\n",
    "!isdir(save_eval_dir) && mkdir(save_eval_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the models\n",
    "\n",
    "We set up the models by defining the ODE dynamics and define two model configurations, `modelargs1` and `modelargs2`, for the respective VAE of each measurement instrument. Specifically, `p` corresponds to the number of time-depedenent variables of each instruments, i.e., the number of test items, and `q` to the number of baseline variables. The `dynamics` are set to the previously defined ODE dynamics. \n",
    "Both models have a `seed` value for reproducibility. \n",
    "The last settings concern the setup of the additional neural network that maps the baseline variables to a set of individual-specific ODE parameters (see the implementation details in the Appendix of the manuscript or the definition of the `odevae` struct in `model.jl` for details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nODEparams = 6\n",
    "dynamics = params_fullinhomogeneous\n",
    "\n",
    "# init models\n",
    "modelargs1 = ModelArgs(p=size(mixeddata.xs1[1],1), \n",
    "                    q=length(mixeddata.xs_baseline[1]), \n",
    "                    dynamics=dynamics,\n",
    "                    bottleneck=false,\n",
    "                    seed=1234,\n",
    "                    scale_sigmoid=2, \n",
    "                    add_diagonal=true \n",
    ")\n",
    "modelargs2 = ModelArgs(p=size(mixeddata.xs2[1],1), \n",
    "                    q=length(mixeddata.xs_baseline[1]), \n",
    "                    dynamics=dynamics,\n",
    "                    bottleneck=false,\n",
    "                    seed=1234,\n",
    "                    scale_sigmoid=2, \n",
    "                    add_diagonal=true \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we initialize the models and set up the training configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = odevae(modelargs1);\n",
    "m2 = odevae(modelargs2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set parameters for the loss function, specifically the weights of the different penalties. In this first illustration, we will use both the ODE (`λ_μpenalty`) and the adversarial penalty (`λ_adversarialpenalty`) (see the Methods Section of the manuscript for more explanation on the loss function and its terms). \n",
    "These parameters are used to create a `LossArgs` object containing the parameters that control the loss function. \n",
    "\n",
    "We then define the training hyperparameters in the `TrainingArgs` struct, controlling the number of training epochs and the learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss args\n",
    "args_joint=LossArgs(\n",
    "    λ_μpenalty=5.0f0,\n",
    "    λ_adversarialpenalty=5.0f0,\n",
    "    λ_variancepenalty=5.0,\n",
    "    variancepenaltytype = :sum_ratio,\n",
    "    variancepenaltyoffset = 1.0f0, \n",
    "    skipt0=true,\n",
    "    weighting=true, \n",
    ")\n",
    "\n",
    "trainingargs_joint=TrainingArgs(warmup=false, epochs=10, lr=0.00003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're ready to train the model. \n",
    "\n",
    "By setting `verbose=true`, we can print out the loss function value after each training epoch. \n",
    "\n",
    "By setting `plotting=true`, we can additionally plot the latent fits of a few randomly selected individuals after each training epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mixed_model!(m1, m2, mixeddata, args_joint, trainingargs_joint, \n",
    "    verbose=true, plotting=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing different penalty versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we now train the model four times, each time with a different configuration of the penalty term weights. We save the models and subsequently evaluate the model predictions and compare to a simple baseline method. We also plot the fitted latent trajectories of a few randomly selected individuals for each model configuration and save the results.\n",
    "\n",
    "This reproduces the results shown in Figure 4 and Table in Section 3.4 in the manuscript. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neither penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We re-initialize the models, define the corresponding loss function arguments, train and save the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = odevae(modelargs1);\n",
    "m2 = odevae(modelargs2);\n",
    "\n",
    "# loss args\n",
    "args_joint=LossArgs(\n",
    "    λ_μpenalty=0.0f0,\n",
    "    λ_adversarialpenalty=0.0f0,\n",
    "    λ_variancepenalty=5.0,\n",
    "    variancepenaltytype = :sum_ratio,\n",
    "    variancepenaltyoffset = 1.0f0, \n",
    "    skipt0=true,\n",
    "    weighting=true, \n",
    ")\n",
    "# prepare training\n",
    "trainingargs_joint=TrainingArgs(warmup=false, epochs=10, lr=0.00003)\n",
    "# train \n",
    "train_mixed_model!(m1, m2, mixeddata, args_joint, trainingargs_joint, verbose=false, plotting=false)\n",
    "# save trained models \n",
    "no_penalty_models = Dict(\"m1\" => deepcopy(m1), \"m2\" => deepcopy(m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the models, we first set up an empty `DataFrame`in which we collect the prediction errors of the ODE and a simple linear baseline model for each penalty configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prederrs_df = DataFrame(\n",
    "    PenaltyType = [],\n",
    "    Dimension = [],\n",
    "    ODE = [],\n",
    "    LinearModel = []\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we evaluate the model predictions, calculate the baseline model and append to the overall dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all, ODEprederrs1, ODEprederrs2 = \n",
    "    eval_prediction(no_penalty_models[\"m1\"], no_penalty_models[\"m2\"], \n",
    "    mixeddata, args_joint, \n",
    "    verbose=false\n",
    ")\n",
    "\n",
    "# baseline linear model\n",
    "prederrdf = fit_baseline_model(df_all, modelargs1.q; verbose=false)\n",
    "\n",
    "# append to overall df \n",
    "prederrdf[!, :PenaltyType] .= \"No penalty\"\n",
    "append!(all_prederrs_df, prederrdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We additionally save exemplary plots of the fitted latent trajectories of a few randomly selected individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we set up the directory for saving the plots and define the selection of individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get selection of individuals \n",
    "Random.seed!(789)\n",
    "selected_ids = rand(mixeddata.ids, 12)\n",
    "\n",
    "# make corresponding directory\n",
    "save_plots_dir = save_eval_dir\n",
    "!isdir(save_plots_dir) && mkdir(save_plots_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we generate and save the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_no_penalty = plot(\n",
    "    plot_selected_ids_final(no_penalty_models[\"m1\"], no_penalty_models[\"m2\"], \n",
    "        mixeddata, args_joint, selected_ids, \n",
    "        colors_points = [\"#3182bd\" \"#9ecae1\"; \"#e6550d\" \"#fdae6b\"], \n",
    "        marker_sizes = [7, 5]\n",
    "    ), \n",
    "    plot_title=\"No ODE or adversarial penalty\"\n",
    ")\n",
    "savefig(plot_no_penalty, joinpath(save_plots_dir, \"no_penalty.pdf\"))\n",
    "plot_no_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only ODE penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We re-initialize the models, define the corresponding loss function arguments, train and save the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = odevae(modelargs1);\n",
    "m2 = odevae(modelargs2);\n",
    "\n",
    "# loss args\n",
    "args_joint=LossArgs(\n",
    "    λ_μpenalty=5.0f0,\n",
    "    λ_adversarialpenalty=0.0f0,\n",
    "    λ_variancepenalty=5.0,\n",
    "    variancepenaltytype = :sum_ratio,\n",
    "    variancepenaltyoffset = 1.0f0, \n",
    "    skipt0=true,\n",
    "    weighting=true, \n",
    ")\n",
    "# prepare training\n",
    "trainingargs_joint=TrainingArgs(warmup=false, epochs=10, lr=0.00003)\n",
    "# train \n",
    "train_mixed_model!(m1, m2, mixeddata, args_joint, trainingargs_joint, verbose=false, plotting=false)\n",
    "\n",
    "only_ODE_penalty_models = Dict(\"m1\" => deepcopy(m1), \"m2\" => deepcopy(m2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we evaluate the model predictions, calculate the baseline model and append to the overall dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all, ODEprederrs1, ODEprederrs2 = \n",
    "    eval_prediction(only_ODE_penalty_models[\"m1\"], only_ODE_penalty_models[\"m2\"], \n",
    "        mixeddata, args_joint, \n",
    "        verbose=false\n",
    ")\n",
    "\n",
    "# baseline model\n",
    "prederrdf = fit_baseline_model(df_all, modelargs1.q; verbose=false)\n",
    "\n",
    "# append to overall df\n",
    "prederrdf[!, :PenaltyType] .= \"Only ODE penalty\"\n",
    "append!(all_prederrs_df, prederrdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we generate and save the plot of the fitted latent trajectories of  selected individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_only_ODE_penalty = plot(\n",
    "    plot_selected_ids_final(only_ODE_penalty_models[\"m1\"], \n",
    "        only_ODE_penalty_models[\"m2\"], \n",
    "        mixeddata, args_joint, selected_ids, \n",
    "        colors_points = [\"#3182bd\" \"#9ecae1\"; \"#e6550d\" \"#fdae6b\"], \n",
    "        marker_sizes = [7, 5]\n",
    "    ), \n",
    "    plot_title=\"Only ODE penalty\"\n",
    ")\n",
    "savefig(plot_only_ODE_penalty, joinpath(save_plots_dir, \"only_ODE_penalty.pdf\"))\n",
    "plot_only_ODE_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only adversarial penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We re-initialize the models, define the corresponding loss function arguments, train and save the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = odevae(modelargs1);\n",
    "m2 = odevae(modelargs2);\n",
    "\n",
    "# loss args\n",
    "args_joint=LossArgs(\n",
    "    λ_μpenalty=0.0f0,# 1.0f0\n",
    "    λ_adversarialpenalty=5.0f0,#1.0f0,\n",
    "    λ_variancepenalty=5.0,\n",
    "    variancepenaltytype = :sum_ratio,\n",
    "    variancepenaltyoffset = 1.0f0, \n",
    "    skipt0=true,\n",
    "    weighting=true, \n",
    ")\n",
    "# prepare training\n",
    "trainingargs_joint=TrainingArgs(warmup=false, epochs=10, lr=0.00003)# lr=0.00008\n",
    "# train \n",
    "train_mixed_model!(m1, m2, mixeddata, args_joint, trainingargs_joint, verbose=false, plotting=false)\n",
    "\n",
    "only_adversarial_penalty_models = Dict(\"m1\" => deepcopy(m1), \"m2\" => deepcopy(m2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we evaluate the model predictions, calculate the baseline model and append to the overall dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all, ODEprederrs1, ODEprederrs2 = \n",
    "    eval_prediction(only_adversarial_penalty_models[\"m1\"], \n",
    "        only_adversarial_penalty_models[\"m2\"], \n",
    "        mixeddata, args_joint, \n",
    "        verbose=false\n",
    ")\n",
    "\n",
    "# baseline model\n",
    "prederrdf = fit_baseline_model(df_all, modelargs1.q; verbose=false)\n",
    "prederrdf[!, :PenaltyType] .= \"Only adversarial penalty\"\n",
    "append!(all_prederrs_df, prederrdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we generate and save the plot of the fitted latent trajectories of  selected individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_only_adversarial_penalty = plot(\n",
    "    plot_selected_ids_final(\n",
    "        only_adversarial_penalty_models[\"m1\"], only_adversarial_penalty_models[\"m2\"], \n",
    "        mixeddata, args_joint, selected_ids, \n",
    "        colors_points = [\"#3182bd\" \"#9ecae1\"; \"#e6550d\" \"#fdae6b\"], \n",
    "        marker_sizes = [7, 5]\n",
    "    ), \n",
    "    plot_title=\"Only adversarial penalty\"\n",
    ")\n",
    "savefig(plot_only_adversarial_penalty, joinpath(save_plots_dir, \"only_adversarial_penalty.pdf\"))\n",
    "plot_only_adversarial_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Both penalties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We re-initialize the models, define the corresponding loss function arguments, train and save the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = odevae(modelargs1);\n",
    "m2 = odevae(modelargs2);\n",
    "\n",
    "# loss args\n",
    "args_joint=LossArgs(\n",
    "    λ_μpenalty=5.0f0,# 1.0f0\n",
    "    λ_adversarialpenalty=5.0f0,#1.0f0,\n",
    "    λ_variancepenalty=5.0,\n",
    "    variancepenaltytype = :sum_ratio,\n",
    "    variancepenaltyoffset = 1.0f0, \n",
    "    skipt0=true,\n",
    "    weighting=true, \n",
    ")\n",
    "# prepare training\n",
    "trainingargs_joint=TrainingArgs(warmup=false, epochs=10, lr=0.00003)# lr=0.00008\n",
    "# train \n",
    "train_mixed_model!(m1, m2, mixeddata, args_joint, trainingargs_joint, verbose=false, plotting=false)\n",
    "\n",
    "ODE_and_adversarial_penalty_models = Dict(\"m1\" => deepcopy(m1), \"m2\" => deepcopy(m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we evaluate the model predictions, calculate the baseline model and append to the overall dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all, ODEprederrs1, ODEprederrs2 = \n",
    "    eval_prediction(ODE_and_adversarial_penalty_models[\"m1\"], \n",
    "    ODE_and_adversarial_penalty_models[\"m2\"], \n",
    "    mixeddata, args_joint, \n",
    "    verbose=false\n",
    ")\n",
    "\n",
    "# baseline model\n",
    "prederrdf = fit_baseline_model(df_all, modelargs1.q; verbose=false)\n",
    "\n",
    "# append to overall df\n",
    "prederrdf[!, :PenaltyType] .= \"ODE and adversarial penalty\"\n",
    "append!(all_prederrs_df, prederrdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we generate and save the plot of the fitted latent trajectories of  selected individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ODE_and_adversarial_penalty = plot(\n",
    "    plot_selected_ids_final(\n",
    "        ODE_and_adversarial_penalty_models[\"m1\"], ODE_and_adversarial_penalty_models[\"m2\"], \n",
    "        mixeddata, args_joint, selected_ids, \n",
    "        colors_points = [\"#3182bd\" \"#9ecae1\"; \"#e6550d\" \"#fdae6b\"], \n",
    "        marker_sizes = [7, 5]\n",
    "    ), \n",
    "    plot_title=\"ODE and adversarial penalty\"\n",
    ")\n",
    "savefig(plot_ODE_and_adversarial_penalty, joinpath(save_plots_dir, \"ODE_and_adversarial_penalty.pdf\"))\n",
    "plot_ODE_and_adversarial_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the final step, we save the overall dataframe containing all prediction errors to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV.write(joinpath(save_eval_dir, \"prediction_errors.csv\"), all_prederrs_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
